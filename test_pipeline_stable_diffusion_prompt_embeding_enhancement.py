import os, torch, cv2
from setup import setup

setup()
from diffusers import StableDiffusionPromptEmbedingEnhancementPipeline

# prompts generated by CLIP Intergrator (reference: https://www.kaggle.com/code/leonidkulyk/lb-0-45836-blip-clip-clip-interrogator/notebook#--9.-Extract-promt-from-images)
prompt_image_pairs = [
    (
        "a man that is standing in front of a counter, a digital rendering, conceptual art, the mighty donut, donut, at the counter",
        "f27825b2c.png",
    ),
    (
        "a cartoon dinosaur with a piece of cheese in its mouth, an illustration of, sumatraism, mmmmm, buttercup eating pizza, pastry lizard",
        "92e911621.png",
    ),
    (
        "a drawing of a robot on a piece of paper, a screenprint, art brut, ((robot)), robot cat, robot design",
        "a4e1c55a9.png",
    ),
    (
        "a circular hole in the middle of a desert, concept art, conceptual art, crater, studying a hell open rift portal, abstract holescape",
        "20057f34d.png",
    ),
    (
        "a man in an astronaut suit walking down a path, a portrait, space art, american astronaut in the forest, astronaut walking, american astronaut",
        "d8edf2e40.png",
    ),
    (
        "a close up of a wooden object on a table, a woodcut, op art, whorl, swirling around, wood art",
        "227ef0887.png",
    ),
    (
        "a painting of a man with a lizard on his head, a surrealist painting, magic realism, magic realism painting, surrealist oil painting, kent monkman",
        "c98f79f71.png",
    ),
]
images_folder_path = "images"
# BUG: turn off "requires_safety_checker" to speed up the process
pipe = StableDiffusionPromptEmbedingEnhancementPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5"
)
device = "cuda" if torch.cuda.is_available() else "mps"
pipe = pipe.to(device)
print("device:", device)

# Recommended if your computer has < 64 GB of RAM
pipe.enable_attention_slicing()  # TODO: might remove this

for prompt, image_name in prompt_image_pairs[4:5]:
    print("prompt:", prompt)
    image = cv2.imread(os.path.join(images_folder_path, image_name))
    image = torch.from_numpy(image).permute(2, 0, 1).unsqueeze(0).float().to(device)
    print("image shape:", image.shape)  # TODO: remove this
    best_prompt_embeds, result = pipe.run_prompt_embeding_enhancement(
        image, prompt, n_epochs=2, batch_size=1, reconstruct_on="latent", visualize=True
    )

# result = {
#     "generated_images_on_epoch": [
#         torch.rand(1, 4, 64, 64).to(device),
#         torch.rand(1, 4, 64, 64).to(device),
#     ]
# }

pil_images = pipe.visualize_prompt_embeding_enhancement(result, reconstruct_on="latent")
# save images
for i, pil_image in enumerate(pil_images):
    pil_image.save(os.path.join("results", f"result_{i}.png"))